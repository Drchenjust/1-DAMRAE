{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d106ee22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import bcolz \n",
    "import importlib\n",
    "import numpy as np\n",
    "import torch.utils.data\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch# import bcolz \n",
    "import importlib\n",
    "import numpy as np\n",
    "import torch.utils.data\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.autograd import Variable\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd028797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class SEWeightModule(nn.Module):\n",
    "    def __init__(self, channels, reduction=4):\n",
    "        super(SEWeightModule, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc1 = nn.Linear(channels,channels//reduction)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(channels//reduction, channels)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.avg_pool(x)\n",
    "        a,b,c, = x.size()\n",
    "        out = out.view(a, b)\n",
    "        \n",
    "        \n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        weight = self.sigmoid(out).view(a, b,1)\n",
    "        return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4385899f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class identity_block(nn.Module):\n",
    "    def __init__(self,channels_in,channels_out,ra):\n",
    "        super(identity_block,self).__init__()\n",
    "        self.channels_in = channels_in\n",
    "        self.channels_out = channels_out\n",
    "        self.stride = 1\n",
    "        self.kernel_size = 3\n",
    "        self.ra=ra\n",
    "        self.conv1 = nn.Conv1d(in_channels=self.channels_in,out_channels=self.channels_out,kernel_size=1,stride=1, padding=0)\n",
    "        self.conv2 = nn.Conv1d(in_channels=self.channels_out,out_channels=self.channels_out,kernel_size=3,stride=1, padding=1)\n",
    "        self.prl = nn.ReLU()\n",
    "        self.conv11 = nn.Conv1d(in_channels=self.channels_out,out_channels=self.channels_out//4,kernel_size=self.kernel_size,stride=self.stride, padding=1,dilation=1)\n",
    "        self.conv12 = nn.Conv1d(in_channels=self.channels_out,out_channels=self.channels_out//4,kernel_size=self.kernel_size,stride=self.stride, padding=3,dilation=3)\n",
    "        self.conv13 = nn.Conv1d(in_channels=self.channels_out,out_channels=self.channels_out//4,kernel_size=self.kernel_size,stride=self.stride, padding=5,dilation=5)\n",
    "        self.conv14 = nn.Conv1d(in_channels=self.channels_out,out_channels=self.channels_out//4,kernel_size=self.kernel_size,stride=self.stride, padding=7,dilation=7)\n",
    "        self.se = SEWeightModule(self.channels_out,self.ra)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(in_channels=self.channels_out,out_channels=self.channels_out,kernel_size=15,stride=1, padding=7)\n",
    "        self.rl = nn.ReLU()\n",
    "        self.maxp = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x=self.conv1(x)\n",
    "        x1=x\n",
    "        x=self.prl(self.conv2(x))\n",
    "        \n",
    "        x11=self.conv11(x)\n",
    "        x12=self.conv12(x)\n",
    "        x13=self.conv13(x)\n",
    "        x14=self.conv14(x)\n",
    "        \n",
    "        output = torch.cat([x11,x12,x13,x14],1)\n",
    "        Woutput= self.se(output )\n",
    "\n",
    "        Woutput=Woutput* output +x1\n",
    "\n",
    "        Woutput=self.rl(Woutput)\n",
    "        Woutput=self.maxp(Woutput)\n",
    "        \n",
    "        return Woutput\n",
    "\n",
    "class identity_block3(nn.Module):\n",
    "    def __init__(self,channels_in,channels_out,ra):\n",
    "        super(identity_block3,self).__init__()\n",
    "        self.channels_in = channels_in\n",
    "        self.channels_out = channels_out\n",
    "        self.stride = 1\n",
    "        self.kernel_size = 3\n",
    "        self.ra=ra\n",
    "        \n",
    "        self.conv1 = nn.ConvTranspose1d(in_channels=self.channels_in,out_channels=self.channels_out,kernel_size=4,stride=2, padding=1)\n",
    "        \n",
    "        self.conv2 = nn.ConvTranspose1d(in_channels=self.channels_out,out_channels=self.channels_out,kernel_size=3,stride=1, padding=1)\n",
    "        self.prl = nn.ReLU()\n",
    "        \n",
    "        self.conv11 = nn.ConvTranspose1d(in_channels=self.channels_out,out_channels=self.channels_out//4,kernel_size=self.kernel_size,stride=self.stride, padding=1,dilation=1)\n",
    "        self.conv12 = nn.ConvTranspose1d(in_channels=self.channels_out,out_channels=self.channels_out//4,kernel_size=self.kernel_size,stride=self.stride, padding=3,dilation=3)\n",
    "        self.conv13 = nn.ConvTranspose1d(in_channels=self.channels_out,out_channels=self.channels_out//4,kernel_size=self.kernel_size,stride=self.stride, padding=5,dilation=5)\n",
    "        self.conv14 = nn.ConvTranspose1d(in_channels=self.channels_out,out_channels=self.channels_out//4,kernel_size=self.kernel_size,stride=self.stride, padding=7,dilation=7)\n",
    "                           \n",
    "    \n",
    "        self.se = SEWeightModule(self.channels_out,self.ra)\n",
    "\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(in_channels=self.channels_out,out_channels=self.channels_out,kernel_size=1,stride=1, padding=0)\n",
    "        self.pr2 = nn.ReLU()\n",
    "\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x=self.conv1(x)\n",
    "        x1=x\n",
    "        x=self.prl(self.conv2(x))\n",
    "        \n",
    "        x11=self.conv11(x)\n",
    "        x12=self.conv12(x)\n",
    "        x13=self.conv13(x)\n",
    "        x14=self.conv14(x)\n",
    "        \n",
    "        output = torch.cat([x11,x12,x13,x14],1)\n",
    "        Woutput= self.se(output )\n",
    "\n",
    "        Woutput=Woutput* output +x1\n",
    "  \n",
    "        \n",
    "        Woutput=self.pr2(Woutput)\n",
    "        Woutput=self.conv3(Woutput)\n",
    "  \n",
    "        \n",
    "        return Woutput\n",
    "\n",
    "class identity_block4(nn.Module):\n",
    "    def __init__(self,channels_in,channels_out,ra):\n",
    "        super(identity_block4,self).__init__()\n",
    "        self.channels_in = channels_in\n",
    "        self.channels_out = channels_out\n",
    "        self.stride = 1\n",
    "        self.kernel_size = 3\n",
    "        self.ra=ra\n",
    "        \n",
    "        self.conv1 = nn.ConvTranspose1d(in_channels=self.channels_in,out_channels=self.channels_out,kernel_size=4,stride=2, padding=1)\n",
    "        \n",
    "        self.conv2 = nn.ConvTranspose1d(in_channels=self.channels_out,out_channels=self.channels_out,kernel_size=3,stride=1, padding=1)\n",
    "        self.prl = nn.ReLU()\n",
    "        \n",
    "        self.conv11 = nn.ConvTranspose1d(in_channels=self.channels_out,out_channels=self.channels_out,kernel_size=self.kernel_size,stride=self.stride, padding=1,dilation=1)\n",
    "\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(in_channels=self.channels_out,out_channels=self.channels_out,kernel_size=1,stride=1, padding=0)\n",
    "        self.pr2 = nn.ReLU()\n",
    "\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x=self.conv1(x)\n",
    "        x1=x\n",
    "        x=self.prl(self.conv2(x))\n",
    "        \n",
    "        x11=self.conv11(x)+x1\n",
    "\n",
    "\n",
    "        Woutput=self.pr2(x11)\n",
    "        Woutput=self.conv3(Woutput)\n",
    "  \n",
    "        \n",
    "        return Woutput\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a904741",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_in=8\n",
    "class DAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DAE,self).__init__()\n",
    "        self.A1 = identity_block(1,16,2)\n",
    "        self.A2 = identity_block(16,32,4)\n",
    "        self.A3 = identity_block(32,64,4)\n",
    "        self.A4 = identity_block(64,128,8)\n",
    "        \n",
    "        self.B1 = identity_block3(128,64,4)\n",
    "        self.B2 = identity_block3(64,32,4)\n",
    "        self.B3 = identity_block3(32,16,2)\n",
    "        self.B4 = identity_block4(16,8,2)\n",
    "        \n",
    "        self.B5= nn.ConvTranspose1d(8,1,3,1,1)\n",
    "        self.SG = nn.Sigmoid()\n",
    "        self.init_weights()\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=S_in, hidden_size=S_in, num_layers=1, batch_first=True,bidirectional=True)\n",
    "        self.fc1 = nn.Linear(S_in*8,S_in)\n",
    "   \n",
    "    def init_weights(self):\n",
    "        \"\"\"\n",
    "        Initialize weights for convolution layers using Xavier initialization.\n",
    "        \"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d) or isinstance(m, nn.ConvTranspose1d):\n",
    "                nn.init.xavier_normal(m.weight.data)      \n",
    "    \n",
    "    def forward(self, x):\n",
    "       \n",
    "        x1=self.A1(x)\n",
    "        x2=self.A2(x1)\n",
    "        x3=self.A3(x2)\n",
    "        x4=self.A4(x3)\n",
    "        h1,h2,h3=x4.shape\n",
    "        x44=x4.reshape(h1*h2,16,8)\n",
    "        x44, h=self.lstm(x44)\n",
    "        o1,o2=torch.split(x44,S_in,2)\n",
    "        x44=(o1+o2)/2\n",
    "        x44=x44.reshape(h1,h2,h3)\n",
    "        x5=self.B1(x44)\n",
    "        x5=x5+x3\n",
    "        x6=self.B2(x5)\n",
    "        x6=x6+x2\n",
    "        x7=self.B3(x6)\n",
    "        x6=x7+x1\n",
    "        x8=self.B4(x7)\n",
    "        x9=self.B5(x8)        \n",
    "        return self.SG(x9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ffee4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv1d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool1d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.activation.Sigmoid'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class '__main__.SEWeightModule'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool1d'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class '__main__.identity_block'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.ConvTranspose1d'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class '__main__.identity_block3'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class '__main__.identity_block4'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "[INFO] Register count_lstm() for <class 'torch.nn.modules.rnn.LSTM'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class '__main__.DAE'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "235465.0 83898208.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:28: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "E:\\Anaconda3\\envs\\torch\\lib\\site-packages\\thop\\vision\\basic_hooks.py:92: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  kernel = torch.DoubleTensor([*(x[0].shape[2:])]) // torch.DoubleTensor(list((m.output_size,))).squeeze()\n"
     ]
    }
   ],
   "source": [
    "model = DAE()\n",
    "from thop import profile\n",
    "model = model.to('cpu')\n",
    "input = torch.randn(1,1,2048)\n",
    "flops, params = profile(model, inputs=(input, ))\n",
    "print(params,flops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abf0206",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11ffec80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:28: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method Module.eval of DAE(\n",
       "  (A1): identity_block(\n",
       "    (conv1): Conv1d(1, 16, kernel_size=(1,), stride=(1,))\n",
       "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (prl): ReLU()\n",
       "    (conv11): Conv1d(16, 4, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv12): Conv1d(16, 4, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "    (conv13): Conv1d(16, 4, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "    (conv14): Conv1d(16, 4, kernel_size=(3,), stride=(1,), padding=(7,), dilation=(7,))\n",
       "    (se): SEWeightModule(\n",
       "      (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "      (fc1): Linear(in_features=16, out_features=8, bias=True)\n",
       "      (relu): ReLU()\n",
       "      (fc2): Linear(in_features=8, out_features=16, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (conv3): Conv1d(16, 16, kernel_size=(15,), stride=(1,), padding=(7,))\n",
       "    (rl): ReLU()\n",
       "    (maxp): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (A2): identity_block(\n",
       "    (conv1): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
       "    (conv2): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (prl): ReLU()\n",
       "    (conv11): Conv1d(32, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv12): Conv1d(32, 8, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "    (conv13): Conv1d(32, 8, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "    (conv14): Conv1d(32, 8, kernel_size=(3,), stride=(1,), padding=(7,), dilation=(7,))\n",
       "    (se): SEWeightModule(\n",
       "      (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "      (fc1): Linear(in_features=32, out_features=8, bias=True)\n",
       "      (relu): ReLU()\n",
       "      (fc2): Linear(in_features=8, out_features=32, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (conv3): Conv1d(32, 32, kernel_size=(15,), stride=(1,), padding=(7,))\n",
       "    (rl): ReLU()\n",
       "    (maxp): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (A3): identity_block(\n",
       "    (conv1): Conv1d(32, 64, kernel_size=(1,), stride=(1,))\n",
       "    (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (prl): ReLU()\n",
       "    (conv11): Conv1d(64, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv12): Conv1d(64, 16, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "    (conv13): Conv1d(64, 16, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "    (conv14): Conv1d(64, 16, kernel_size=(3,), stride=(1,), padding=(7,), dilation=(7,))\n",
       "    (se): SEWeightModule(\n",
       "      (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "      (fc1): Linear(in_features=64, out_features=16, bias=True)\n",
       "      (relu): ReLU()\n",
       "      (fc2): Linear(in_features=16, out_features=64, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (conv3): Conv1d(64, 64, kernel_size=(15,), stride=(1,), padding=(7,))\n",
       "    (rl): ReLU()\n",
       "    (maxp): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (A4): identity_block(\n",
       "    (conv1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "    (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (prl): ReLU()\n",
       "    (conv11): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv12): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "    (conv13): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "    (conv14): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(7,), dilation=(7,))\n",
       "    (se): SEWeightModule(\n",
       "      (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "      (fc1): Linear(in_features=128, out_features=16, bias=True)\n",
       "      (relu): ReLU()\n",
       "      (fc2): Linear(in_features=16, out_features=128, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (conv3): Conv1d(128, 128, kernel_size=(15,), stride=(1,), padding=(7,))\n",
       "    (rl): ReLU()\n",
       "    (maxp): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (B1): identity_block3(\n",
       "    (conv1): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "    (conv2): ConvTranspose1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (prl): ReLU()\n",
       "    (conv11): ConvTranspose1d(64, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv12): ConvTranspose1d(64, 16, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "    (conv13): ConvTranspose1d(64, 16, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "    (conv14): ConvTranspose1d(64, 16, kernel_size=(3,), stride=(1,), padding=(7,), dilation=(7,))\n",
       "    (se): SEWeightModule(\n",
       "      (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "      (fc1): Linear(in_features=64, out_features=16, bias=True)\n",
       "      (relu): ReLU()\n",
       "      (fc2): Linear(in_features=16, out_features=64, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (conv3): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "    (pr2): ReLU()\n",
       "  )\n",
       "  (B2): identity_block3(\n",
       "    (conv1): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "    (conv2): ConvTranspose1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (prl): ReLU()\n",
       "    (conv11): ConvTranspose1d(32, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv12): ConvTranspose1d(32, 8, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "    (conv13): ConvTranspose1d(32, 8, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "    (conv14): ConvTranspose1d(32, 8, kernel_size=(3,), stride=(1,), padding=(7,), dilation=(7,))\n",
       "    (se): SEWeightModule(\n",
       "      (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "      (fc1): Linear(in_features=32, out_features=8, bias=True)\n",
       "      (relu): ReLU()\n",
       "      (fc2): Linear(in_features=8, out_features=32, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (conv3): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
       "    (pr2): ReLU()\n",
       "  )\n",
       "  (B3): identity_block3(\n",
       "    (conv1): ConvTranspose1d(32, 16, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "    (conv2): ConvTranspose1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (prl): ReLU()\n",
       "    (conv11): ConvTranspose1d(16, 4, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv12): ConvTranspose1d(16, 4, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "    (conv13): ConvTranspose1d(16, 4, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "    (conv14): ConvTranspose1d(16, 4, kernel_size=(3,), stride=(1,), padding=(7,), dilation=(7,))\n",
       "    (se): SEWeightModule(\n",
       "      (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "      (fc1): Linear(in_features=16, out_features=8, bias=True)\n",
       "      (relu): ReLU()\n",
       "      (fc2): Linear(in_features=8, out_features=16, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (conv3): Conv1d(16, 16, kernel_size=(1,), stride=(1,))\n",
       "    (pr2): ReLU()\n",
       "  )\n",
       "  (B4): identity_block4(\n",
       "    (conv1): ConvTranspose1d(16, 8, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "    (conv2): ConvTranspose1d(8, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (prl): ReLU()\n",
       "    (conv11): ConvTranspose1d(8, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv3): Conv1d(8, 8, kernel_size=(1,), stride=(1,))\n",
       "    (pr2): ReLU()\n",
       "  )\n",
       "  (B5): ConvTranspose1d(8, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (SG): Sigmoid()\n",
       "  (lstm): LSTM(8, 8, batch_first=True, bidirectional=True)\n",
       "  (fc1): Linear(in_features=64, out_features=8, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ONEDAMRAE = DAE()\n",
    "ONEDAMRAE.load_state_dict(torch.load('C:/Users/cccc/Desktop/1-DAMRAE/WEIGHT.pth'))\n",
    "ONEDAMRAE.cpu().eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "504906a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['__header__', '__version__', '__globals__', 'test'])\n",
      "0.2756278725995399\n",
      "0.9843764258662282\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "\n",
    "dict_mat = loadmat(\"C:\\\\Users\\\\cccc\\\\Desktop\\\\1-DAMRAE\\\\TEST_NAM_SJR_neg10_SNR10.mat\")\n",
    "print(type(dict_mat))\n",
    "print(dict_mat.keys())\n",
    "test = np.matrix.transpose(dict_mat[\"test\"])    #echo+AWGN+jamming\n",
    "dict_mat = loadmat(\"C:\\\\Users\\\\cccc\\\\Desktop\\\\1-DAMRAE\\\\pure.mat\")\n",
    "testb = np.matrix.transpose(dict_mat[\"testb\"])  #pure echo\n",
    "\n",
    "S1=test*2-1  #Normalized → -1 to 1\n",
    "S2=testb*2-1\n",
    "P1=np.zeros(len(S1))\n",
    "for i in range(len(S1)):\n",
    "    P1[i]=np.abs(np.mean(S1[i,:]*S2[i,:]))/np.sqrt(np.abs(np.mean(S1[i,:]*S1[i,:]))*np.abs(np.mean(S2[i,:]*S2[i,:])))\n",
    "print(np.mean(P1)) #   Waveform similarity between the received signal and the pure echo\n",
    "\n",
    "test=torch.from_numpy(test).float().view(len(S1),1,2048)\n",
    "decoder_output= ONEDAMRAE(test)\n",
    "decoder_output = decoder_output.detach().cpu().numpy()\n",
    "decoder_output.shape\n",
    "from scipy.io import savemat\n",
    "decoder_output.shape\n",
    "import numpy as np\n",
    "from scipy import io\n",
    "\n",
    "S3=decoder_output*2-1\n",
    "P2=np.zeros(len(S2))\n",
    "for i in range(len(S2)):\n",
    "    P2[i]=np.abs(np.mean(S2[i,:]*S3[i,:]))/np.sqrt(np.abs(np.mean(S2[i,:]*S2[i,:]))*np.abs(np.mean(S3[i,:]*S3[i,:])))\n",
    "print(np.mean(P2)) #   Waveform similarity between the recovered signal and the pure echo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bc7289a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['__header__', '__version__', '__globals__', 'test'])\n",
      "0.31405597555918485\n",
      "0.9932307727289404\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "\n",
    "dict_mat = loadmat(\"C:\\\\Users\\\\cccc\\\\Desktop\\\\1-DAMRAE\\\\TEST_NFM_SJR_neg10_SNR10.mat\")\n",
    "print(type(dict_mat))\n",
    "print(dict_mat.keys())\n",
    "test = np.matrix.transpose(dict_mat[\"test\"])    #echo+AWGN+jamming\n",
    "dict_mat = loadmat(\"C:\\\\Users\\\\cccc\\\\Desktop\\\\1-DAMRAE\\\\pure.mat\")\n",
    "testb = np.matrix.transpose(dict_mat[\"testb\"])  #pure echo\n",
    "\n",
    "S1=test*2-1    #Normalized → -1 to 1\n",
    "S2=testb*2-1\n",
    "P1=np.zeros(len(S1))\n",
    "for i in range(len(S1)):\n",
    "    P1[i]=np.abs(np.mean(S1[i,:]*S2[i,:]))/np.sqrt(np.abs(np.mean(S1[i,:]*S1[i,:]))*np.abs(np.mean(S2[i,:]*S2[i,:])))\n",
    "print(np.mean(P1)) #   Waveform similarity between the received signal and the pure echo\n",
    "\n",
    "test=torch.from_numpy(test).float().view(len(S1),1,2048)\n",
    "decoder_output= ONEDAMRAE(test)\n",
    "decoder_output = decoder_output.detach().cpu().numpy()\n",
    "decoder_output.shape\n",
    "from scipy.io import savemat\n",
    "decoder_output.shape\n",
    "import numpy as np\n",
    "from scipy import io\n",
    "\n",
    "S3=decoder_output*2-1\n",
    "P2=np.zeros(len(S2))\n",
    "for i in range(len(S2)):\n",
    "    P2[i]=np.abs(np.mean(S2[i,:]*S3[i,:]))/np.sqrt(np.abs(np.mean(S2[i,:]*S2[i,:]))*np.abs(np.mean(S3[i,:]*S3[i,:])))\n",
    "print(np.mean(P2)) #   Waveform similarity between the recovered signal and the pure echo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65abe2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['__header__', '__version__', '__globals__', 'test'])\n",
      "0.3764977185838127\n",
      "0.9938716028584441\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "\n",
    "dict_mat = loadmat(\"C:\\\\Users\\\\cccc\\\\Desktop\\\\1-DAMRAE\\\\TEST_VV_SJR_neg10_SNR10.mat\")\n",
    "print(type(dict_mat))\n",
    "print(dict_mat.keys())\n",
    "test = np.matrix.transpose(dict_mat[\"test\"])    #echo+AWGN+jamming\n",
    "dict_mat = loadmat(\"C:\\\\Users\\\\cccc\\\\Desktop\\\\1-DAMRAE\\\\pure.mat\")\n",
    "testb = np.matrix.transpose(dict_mat[\"testb\"])  #pure echo\n",
    "\n",
    "S1=test*2-1    #Normalized → -1 to 1\n",
    "S2=testb*2-1\n",
    "P1=np.zeros(len(S1))\n",
    "for i in range(len(S1)):\n",
    "    P1[i]=np.abs(np.mean(S1[i,:]*S2[i,:]))/np.sqrt(np.abs(np.mean(S1[i,:]*S1[i,:]))*np.abs(np.mean(S2[i,:]*S2[i,:])))\n",
    "print(np.mean(P1)) #   Waveform similarity between the received signal and the pure echo\n",
    "\n",
    "test=torch.from_numpy(test).float().view(len(S1),1,2048)\n",
    "decoder_output= ONEDAMRAE(test)\n",
    "decoder_output = decoder_output.detach().cpu().numpy()\n",
    "decoder_output.shape\n",
    "from scipy.io import savemat\n",
    "decoder_output.shape\n",
    "import numpy as np\n",
    "from scipy import io\n",
    "\n",
    "S3=decoder_output*2-1\n",
    "P2=np.zeros(len(S2))\n",
    "for i in range(len(S2)):\n",
    "    P2[i]=np.abs(np.mean(S2[i,:]*S3[i,:]))/np.sqrt(np.abs(np.mean(S2[i,:]*S2[i,:]))*np.abs(np.mean(S3[i,:]*S3[i,:])))\n",
    "print(np.mean(P2)) #   Waveform similarity between the recovered signal and the pure echo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a484423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['__header__', '__version__', '__globals__', 'test'])\n",
      "0.31397498464119616\n",
      "0.9969539508290963\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "\n",
    "dict_mat = loadmat(\"C:\\\\Users\\\\cccc\\\\Desktop\\\\1-DAMRAE\\\\TEST_DV_SJR_neg10_SNR10.mat\")\n",
    "print(type(dict_mat))\n",
    "print(dict_mat.keys())\n",
    "test = np.matrix.transpose(dict_mat[\"test\"])    #echo+AWGN+jamming\n",
    "dict_mat = loadmat(\"C:\\\\Users\\\\cccc\\\\Desktop\\\\1-DAMRAE\\\\pure.mat\")\n",
    "testb = np.matrix.transpose(dict_mat[\"testb\"])  #pure echo\n",
    "\n",
    "S1=test*2-1    #Normalized → -1 to 1\n",
    "S2=testb*2-1\n",
    "P1=np.zeros(len(S1))\n",
    "for i in range(len(S1)):\n",
    "    P1[i]=np.abs(np.mean(S1[i,:]*S2[i,:]))/np.sqrt(np.abs(np.mean(S1[i,:]*S1[i,:]))*np.abs(np.mean(S2[i,:]*S2[i,:])))\n",
    "print(np.mean(P1)) #   Waveform similarity between the received signal and the pure echo\n",
    "\n",
    "test=torch.from_numpy(test).float().view(len(S1),1,2048)\n",
    "decoder_output= ONEDAMRAE(test)\n",
    "decoder_output = decoder_output.detach().cpu().numpy()\n",
    "decoder_output.shape\n",
    "from scipy.io import savemat\n",
    "decoder_output.shape\n",
    "import numpy as np\n",
    "from scipy import io\n",
    "\n",
    "S3=decoder_output*2-1\n",
    "P2=np.zeros(len(S2))\n",
    "for i in range(len(S2)):\n",
    "    P2[i]=np.abs(np.mean(S2[i,:]*S3[i,:]))/np.sqrt(np.abs(np.mean(S2[i,:]*S2[i,:]))*np.abs(np.mean(S3[i,:]*S3[i,:])))\n",
    "print(np.mean(P2)) #   Waveform similarity between the recovered signal and the pure echo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d25497f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['__header__', '__version__', '__globals__', 'test'])\n",
      "0.37640278260776366\n",
      "0.9966449452061142\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "\n",
    "dict_mat = loadmat(\"C:\\\\Users\\\\cccc\\\\Desktop\\\\1-DAMRAE\\\\TEST_DVV_SJR_neg10_SNR10.mat\")\n",
    "print(type(dict_mat))\n",
    "print(dict_mat.keys())\n",
    "test = np.matrix.transpose(dict_mat[\"test\"])    #echo+AWGN+jamming\n",
    "dict_mat = loadmat(\"C:\\\\Users\\\\cccc\\\\Desktop\\\\1-DAMRAE\\\\pure.mat\")\n",
    "testb = np.matrix.transpose(dict_mat[\"testb\"])  #pure echo\n",
    "\n",
    "S1=test*2-1    #Normalized → -1 to 1\n",
    "S2=testb*2-1\n",
    "P1=np.zeros(len(S1))\n",
    "for i in range(len(S1)):\n",
    "    P1[i]=np.abs(np.mean(S1[i,:]*S2[i,:]))/np.sqrt(np.abs(np.mean(S1[i,:]*S1[i,:]))*np.abs(np.mean(S2[i,:]*S2[i,:])))\n",
    "print(np.mean(P1)) #   Waveform similarity between the received signal and the pure echo\n",
    "\n",
    "test=torch.from_numpy(test).float().view(len(S1),1,2048)\n",
    "decoder_output= ONEDAMRAE(test)\n",
    "decoder_output = decoder_output.detach().cpu().numpy()\n",
    "decoder_output.shape\n",
    "from scipy.io import savemat\n",
    "decoder_output.shape\n",
    "import numpy as np\n",
    "from scipy import io\n",
    "\n",
    "S3=decoder_output*2-1\n",
    "P2=np.zeros(len(S2))\n",
    "for i in range(len(S2)):\n",
    "    P2[i]=np.abs(np.mean(S2[i,:]*S3[i,:]))/np.sqrt(np.abs(np.mean(S2[i,:]*S2[i,:]))*np.abs(np.mean(S3[i,:]*S3[i,:])))\n",
    "print(np.mean(P2)) #   Waveform similarity between the recovered signal and the pure echo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cb00d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['__header__', '__version__', '__globals__', 'test'])\n",
      "0.38276868741674497\n",
      "0.9090277899733333\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "\n",
    "dict_mat = loadmat(\"C:\\\\Users\\\\cccc\\\\Desktop\\\\1-DAMRAE\\\\TEST_OODNPM_SJR_neg8_SNR10.mat\")\n",
    "print(type(dict_mat))\n",
    "print(dict_mat.keys())\n",
    "test = np.matrix.transpose(dict_mat[\"test\"])    #echo+AWGN+jamming\n",
    "dict_mat = loadmat(\"C:\\\\Users\\\\cccc\\\\Desktop\\\\1-DAMRAE\\\\pure.mat\")\n",
    "testb = np.matrix.transpose(dict_mat[\"testb\"])  #pure echo\n",
    "\n",
    "S1=test*2-1    #Normalized → -1 to 1\n",
    "S2=testb*2-1\n",
    "P1=np.zeros(len(S1))\n",
    "for i in range(len(S1)):\n",
    "    P1[i]=np.abs(np.mean(S1[i,:]*S2[i,:]))/np.sqrt(np.abs(np.mean(S1[i,:]*S1[i,:]))*np.abs(np.mean(S2[i,:]*S2[i,:])))\n",
    "print(np.mean(P1)) #   Waveform similarity between the received signal and the pure echo\n",
    "\n",
    "test=torch.from_numpy(test).float().view(len(S1),1,2048)\n",
    "decoder_output= ONEDAMRAE(test)\n",
    "decoder_output = decoder_output.detach().cpu().numpy()\n",
    "decoder_output.shape\n",
    "from scipy.io import savemat\n",
    "decoder_output.shape\n",
    "import numpy as np\n",
    "from scipy import io\n",
    "\n",
    "S3=decoder_output*2-1\n",
    "P2=np.zeros(len(S2))\n",
    "for i in range(len(S2)):\n",
    "    P2[i]=np.abs(np.mean(S2[i,:]*S3[i,:]))/np.sqrt(np.abs(np.mean(S2[i,:]*S2[i,:]))*np.abs(np.mean(S3[i,:]*S3[i,:])))\n",
    "print(np.mean(P2)) #   Waveform similarity between the recovered signal and the pure echo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a20b2cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['__header__', '__version__', '__globals__', 'test'])\n",
      "0.2752818838236201\n",
      "0.9325394177958714\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "\n",
    "dict_mat = loadmat(\"C:\\\\Users\\\\cccc\\\\Desktop\\\\1-DAMRAE\\\\TEST_OODCJ_SJR_neg8_SNR10.mat\")\n",
    "print(type(dict_mat))\n",
    "print(dict_mat.keys())\n",
    "test = np.matrix.transpose(dict_mat[\"test\"])    #echo+AWGN+jamming\n",
    "dict_mat = loadmat(\"C:\\\\Users\\\\cccc\\\\Desktop\\\\1-DAMRAE\\\\pure.mat\")\n",
    "testb = np.matrix.transpose(dict_mat[\"testb\"])  #pure echo\n",
    "\n",
    "S1=test*2-1    #Normalized → -1 to 1\n",
    "S2=testb*2-1\n",
    "P1=np.zeros(len(S1))\n",
    "for i in range(len(S1)):\n",
    "    P1[i]=np.abs(np.mean(S1[i,:]*S2[i,:]))/np.sqrt(np.abs(np.mean(S1[i,:]*S1[i,:]))*np.abs(np.mean(S2[i,:]*S2[i,:])))\n",
    "print(np.mean(P1)) #   Waveform similarity between the received signal and the pure echo\n",
    "\n",
    "test=torch.from_numpy(test).float().view(len(S1),1,2048)\n",
    "decoder_output= ONEDAMRAE(test)\n",
    "decoder_output = decoder_output.detach().cpu().numpy()\n",
    "decoder_output.shape\n",
    "from scipy.io import savemat\n",
    "decoder_output.shape\n",
    "import numpy as np\n",
    "from scipy import io\n",
    "\n",
    "S3=decoder_output*2-1\n",
    "P2=np.zeros(len(S2))\n",
    "for i in range(len(S2)):\n",
    "    P2[i]=np.abs(np.mean(S2[i,:]*S3[i,:]))/np.sqrt(np.abs(np.mean(S2[i,:]*S2[i,:]))*np.abs(np.mean(S3[i,:]*S3[i,:])))\n",
    "print(np.mean(P2)) #   Waveform similarity between the recovered signal and the pure echo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6739008",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
